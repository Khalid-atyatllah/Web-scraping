import requests
from bs4 import BeautifulSoup
import csv
import pandas as pd

url = "https://www.jumia.ma/catalog/?q=adaptateur+iphone+usb"
page = requests.get(url)
soup = BeautifulSoup(page.text, 'html.parser')

items = soup.find_all('article', class_='prd _fb col c-prd')

data_list = []

for article in items:
    price = article.find('div', class_="prc").get_text()
    name = article.find('h3', class_='name').get_text()
    stars_div = article.find('div', class_="stars _s")
    img_url = article.find('img', class_='img')['data-src']

    if stars_div:
        star_rating_text = stars_div.get_text(strip=True)
        stars = "/".join(star_rating_text.split(" out of "))
    else:
        stars = "N/A"

    data = [price, name, stars, img_url]
    data_list.append(data)

header = ['price', 'name', 'stars', 'img_url']

with open('jumiaWebScraperDataset.csv', 'w', newline='', encoding='UTF8') as f:
    writer = csv.writer(f)
    writer.writerow(header)
    writer.writerows(data_list)

df = pd.read_csv('jumiaWebScraperDataset.csv')

df
